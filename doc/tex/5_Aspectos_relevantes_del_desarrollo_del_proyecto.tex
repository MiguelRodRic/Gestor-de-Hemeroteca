\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

En este capítulo se desarrollarán en profundidad aspectos sólo mencionados en capítulos previos, relacionados tanto con conceptos teóricos como con las técnicas y herramientas, además de dar explicación a cuestiones relevantes respecto de la aplicación o de su desarrollo.

\section{Conceptos avanzados de Bag of Words}

Además de lo mencionado en los conceptos teóricos, hay diferentes matices dentro del bag of words que merecen la pena ser explicados con más detalle, ya que fueron relevantes en la implementación del proyecto.

\subsection{Stopwords}

Se conoce como \emph{``stopwords''} (o palabras vacías) al conjunto de palabras prefijadas por el programador (o por el usuario, si se le da la opción) que no queremos que se tengan en cuenta a la hora de formar un vocabulario con el texto de entrada. 

Cuando se está dando forma al modelo, se le pasa este conjunto a la herramienta que va a transformar el texto en un vocabulario con frecuencia de palabras, de modo que ésta filtra las palabras mencionadas para eliminar el ``ruido'' y de forma consecuente, aumentar la relevancia del resto de palabras que almacene.

Habitualmente, lo que se busca evitar son las palabras que tienen menos significado propio dentro de una frase. Dicho de otra manera, las primeras palabras que deben ser filtradas son artículos, determinantes, preposiciones... que son las menos interesantes en una frase.

En este proyecto, se hizo uso de un conjunto de \emph{stopwords} de palabras en español que viene incluido en la librería de NLTK \cite{nltk}, que contiene las palabras de la siguiente lista:

\begin{displayquote}
\textbf{  de, la, que, el, en, y, a, los, del, se, las, por, un, para, con, no, una, su, al, lo, como, más, pero, sus, le, ya, o, este, porque, esta, entre, sí, cuando, muy, sin, sobre,
 también, me, hasta, hay, donde, quien, desde, todo, nos, durante, todos, uno, les, ni, contra, otros, ese, eso, ante, ellos, e, esto, mí, antes, algunos, qué, unos, yo, otro, otras, otra, él, tanto, esa, estos, mucho, quienes, nada, muchos, cual, poco, ella, estar, estas, algunas, algo, nosotros, mi, mis, tú, te, ti, tu, tus, ellas, nosotras, vosostros, vosostras, os, mío, mía, míos, mías, tuyo, tuya, tuyos, tuyas, suyo, suya, suyos, suyas, nuestro, nuestra, nuestros, nuestras, vuestra, vuestros, vuestras, esos, esas, estoy, estás, está, estamos, estáis, están, esté, estés, estemos, estéis, estén, estaré, estarás, estará, estaremos, estaréis, estarán, estaría, estarías, estaríamos, estaríais, estarían, estaba, estabas, 
 estábamos, estabais, estaban, estuve, estuviste, estuvo, estuvimos, estuvisteis, estuvieron, estuviera, estuvieras, estuviéramos, estuvierais, estuvieran, estuviese, estuvieses, 
 estuviésemos, estuvieseis, estuviesen, estando, estado, estada, estados, estadas, estad, he, has, ha, hemos, habéis, han, haya, hayas, hayamos, hayáis, hayan, habré, habrás, habrá, habremos, habréis, habrán, habría, habrías, habríamos, habríais, habrían, había, habías, habíamos, habíais, habían, 
 hube, hubiste, hubo, hubimos, hubisteis, hubieron, hubiera, hubieras, hubiéramos, hubierais, hubieran, hubiese,
 hubieses, hubiésemos, hubieseis, hubiesen, habiendo, habido, habida, habidos, habidas, soy, eres, es, somos, sois, son, sea, 
 seas, seamos, seáis, sean, seré, serás, será, seremos, 
 seréis, serán, sería, serías, seríamos, seríais, serían, era, 
 eras, éramos, erais, eran, fui, fuiste, fue, fuimos, 
 fuisteis, fueron, fuera, fueras, fuéramos, fuerais, fueran, fuese, fueses, fuésemos, fueseis, fuesen, sintiendo, sentido, sentida, sentidos, sentidas, siente, sentid, tengo, 
 tienes, tiene, tenemos, tenéis, tienen, tenga, tengas, tengamos, tengáis, tengan, tendré, tendrás, tendrá, tendremos, tendréis, tendrán, tendría, tendrías, tendríamos, tendríais, 
 tendrían, tenía, tenías, teníamos, teníais, tenían, tuve, tuviste, tuvo, tuvimos, tuvisteis, tuvieron, tuviera, tuvieras, tuviéramos, tuvierais, tuvieran, tuviese, tuvieses, tuviésemos, 
 tuvieseis, tuviesen, teniendo, tenido, tenida, tenidos, tenidas
}
\end{displayquote}


Ya que estas palabras son muy frecuentes en la mayoría de frases en español, no sólo restaban importancia a las verdaderamente relevantes, si no que incluso podrían ser consideradas de las más relevantes simplemente por su frecuencia de aparición, lo cuál restaría mucha calidad a la predicción posterior. 

Cabe destacar que ésto no soluciona todo el problema, ya que en los textos de las noticias podrían aparecer alguna de estas palabras con mayúsculas, sin tildes, u otras palabras no relevantes que evitarían el filtro. No obstante, con este filtro ya se puede asegurar una cierta calidad en las predicciones de forma general.

\subsection{Normalización de las frecuencias}

Como se ha mencionado previamente, lo habitual es que una predicción de clases basada en un bag of words se realice basando la clasificación en la frecuencia de aparición de determinadas palabras en los textos de cada una de las clases.

Para poder medir esta frecuencia, no es suficiente con tener los vocabularios de cada clase con sus frecuencias, pues no es una medida lo suficientemente precisa. Lo que se debe realizar es una normalización de estas frecuencias, teniendo en cuenta los siguientes cálculos \cite{spamtutorial}

\begin{itemize}

\item Frecuencia normalizada de una palabra en una clase:

\[ \mathit{FrecuenciaClase1}[ \mathit{palabra}] = \frac{\mathit{apariciones}[ \mathit{palabra}]}{\mathit{numeroNoticias}[ \mathit{Clase1}]} \]

Se recomienda añadir una aparición por defecto, para evitar divisiones entre 0.

\item Ratio de pertenencia de una palabra a una clase, en el caso de que el problema sólo tenga 2 clases:

\[ \mathit{RatioClase1}[ \mathit{palabra}] = \frac{\mathit{FrecuenciaClase1}[ \mathit{palabra}]}{\mathit{FrecuenciaClase2}[ \mathit{palabra}]} \]

Si, siguiendo el ejemplo que mencionamos en los conceptos teóricos, tenemos que la palabra ``salud'' tiene un mayor ratio en la clase ``En contra de los fumadores" que en ``A favor de los fumadores", se puede anticipar que la próxima vez que se reciba una frase o texto con la palabra ``salud'', tendrá mayores posibilidades de pertenecer a la clase ``En contra de los fumadores''.

\end{itemize}

Realizando estos simples cálculos y ordenando las palabras en función de sus respectivos ratio, se puede deducir cuáles serán las palabras más influyentes a la hora de saber si una frase o un texto se corresponde con una clase u otra.

\section{Resultados de la explicación de la predicción}

Una de las funcionalidades que más peso tiene en el producto final es el de mostrar una explicación de la predicción realizada sobre una noticia, respecto de un Dataset determinado. 

Siguiendo la filosofía de ``no reinventar la rueda'', para parte de la programación de este apartado hemos usado la librería Lime, de la cual se habla en el apartado de ``Técnicas y Herramientas'', y que permite obtener una explicación de cualquier clasificación realizada, ya sea usando texto o imagen, y preferiblemente usando Scikit-learn como librería para practicar la minería de datos.

Se ha aprovechado la posibilidad que ofrece Lime de devolver esta explicación con un formato de bloque HTML, en el cuál a su vez se incluyen tres apartados distintos:

\begin{itemize}

\item Barras de progreso que indican las probabilidades de pertenencia a cada una de las clases.

\item Un gráfico de barras en el que se muestran por orden las palabras más influyentes a la hora de tomar la decisión, ya sea para una clase o para otra.

\item El texto de prueba entero que se ha recibido, resaltando en él las palabras que se han incluido en el gráfico del punto anterior, para que el usuario pueda observar estas palabras en su contexto real (antes de hacer el bag of words), y no simplemente en la lista de palabras influyentes.

\end{itemize}

\imagen{CapturaExplicacion}{Resultados HTML de la explicación}

En la imagen se observan de forma diferenciada los tres apartados, y se le ofrece al usuario la posibilidad de, después de haber estudiado con detenimiento los detalles de la predicción, decidir etiquetar esta noticia en concordancia con la predicción realizada.

Puede que al usar la aplicación de la sensación de que el estilo visual de estos resultados de la explicación no encaja completamente con el estilo visual del resto de las pestañas. Esto es debido a que se inyecta directamente el bloque HTML sin alterar que devuelve Lime en la pestaña antes de cargar la misma. Debido a limitaciones de tiempo, era más productivo aprovechar este código HTML ya escrito que solamente recibir de Lime los datos y dedicar tiempo extra a escribir el código HTML y las funciones de Javascript necesarias para preparar la misma vista de resultados pero con otros estilos diferentes. De nuevo, se ha decidido seguir el razonamiento de que ``no hay que reinventar la rueda''.

\section{Pruebas de clasificación}

Como ya se ha mencionado en el apartado de conceptos teóricos, hay más de un clasificador que se tuvo en cuenta en el aprendizaje automático de textos. A continuación haremos una comparativa en la que se verá cómo afectaban al rendimiento y precisión cada caso.

\subsection{Predicción de clase}

Cuando se muestra una muestra de resultados de noticias, se puede observar una barra que indica las probabilidades de esa etiqueta de pertenecer a una clase u a otra. Para conseguir ésto hay que realizar predicciones por medio del aprendizaje automático, como ya se ha comentado en otras secciones.

Los clasificadores que se han comparado han sido un clasificador de \emph{random forest} y un clasificador \emph{Naive Bayes}. En el primer caso, como podemos indicar cuántos árboles queremos que formen el bosque, hemos realizado pruebas de rendimiento con varios casos, como se puede ver en la siguiente imagen:

\imagen{clasificacionchart}{Comparativa de rendimiento en función del número de árboles}

Como se puede observar, a medida que desciende el número de árboles, más rápidas son las predicciones. No obstante, hay que tener en cuenta que la variación de las mismas sí que se reduce con más árboles. Por tanto, disminuir mucho el número de árboles lleva a predicciones poco estables y en muchos casos, equivocadas. Con 90 árboles, los tiempos de carga son aceptables y los resultados siguen siendo bastante estables, así que fue la cantidad que se escogió como ganadora.

En el caso del clasificador \emph{Naive Bayes}, los tiempos de carga eran mínimos, tardaba entre 3 y 4 segundos en realizar las predicciones. El problema es que este tipo de clasificador no usa \emph{Bagging}, y por tanto, todas las predicciones que haga no van a tener un componente aleatorio y no van a cambiar a no se que cambie el conjunto de entrenamiento. Dicho de otra manera, si el clasificador está realizando predicciones erróneas, no hay manera de saberlo pues no va a variar los resultados con repetidas pruebas.

\subsection{Creación de explicaciones}

En el caso de las explicaciones, la perspectiva es notablemente distinta. Dado que se usa la librería \emph{Lime} para generarlas, como ya se ha explicado en la parte de herramientas, los tiempos de carga no dependen exclusivamente del tipo de clasificación que se esté realizando. 

De hecho, realizando pruebas similares a las del apartado anterior, se ha podido ver que para crear una explicación para una noticia tarda siempre lo mismo, ya sea un clasificador \emph{Random Forest} o un \emph{Naive Bayes}, con márgenes de unos 5 segundos. De hecho, aún probando con cantidades de árboles muy distintas (de 20 a 500), sólo se ha notado efecto en el rendimiento a partir de los 400 árboles, aproximadamente. Usando esto a como una ventaja, se ha podido aumentar mucho el número de árboles en comparación con los que se usan en la predicción, lo cual aumentará la precisión promedio de los resultados.

Desafortunadamente, los tiempos de carga de \emph{Lime} son perceptibles en comparación con el resto de operaciones de la herramienta, y se puede hacer poco a nivel de código para mejorar esta situación.

\section{Experimentación en Jupyter}

Debido a los problemas que se mencionan a continuación, la opción de implementar la aplicación web basada en notebooks de Jupyter tuvo que ser descartada en pleno desarrollo del proyecto.
No obstante, los primeros meses del mismo fueron dedicados casi completamente a la experimentación de funcionalidades en esta plataforma. De hecho, en el repositorio del proyecto se encuentra un grupo de notebooks que no llegaron a formar parte del producto final, pero que a su vez contienen funcionalidad avanzada que tampoco pudo incluirse en la aplicación de Flask. Los ejemplos más interesantes son los siguientes:

\begin{itemize}

\item \emph{Web Scraping} avanzado: Antes de enfocar el web scraping en los RSS de los medios de comunicación. Se realizaron dos prototipos de web scraping convencional en la página web de los periódicos Público y ElDiario.

Cabe destacar que este \emph{web scraping} estaba más perfeccionado que el que hay en el código final, pero al mismo tiempo estaba demasiado personalizado para cada medio en concreto, y no podía replicarse con facilidad para otros portales web. En la versión final, se pueden añadir más medios con menos esfuerzos, a costa de sacrificar calidad en el texto extraído de cada noticia.

\item Clasificación con \emph{Bag of Words}: En algunos de los notebooks hay muestras de las primeras pruebas de clasificación de texto que se hicieron usando Scikit-Learn, en las que además se puede ver como se usan otros elementos como la validación cruzada para crear conjuntos de entrenamiento y de prueba a partir de los mismos elementos iniciales. Como en la aplicación final sabemos a ciencia cierta cuál son las noticias de entrenamiento y cuál sobre la que hay que hacer la predicción, no hace falta usar esta validación cruzada.

\item Lectura más exhaustiva de PDF: También hay un apartado de notebooks dedicado a la lectura de PDF y extracción de su texto, donde se implementaron los primeros acercamientos antes de programar la versión final en la aplicación de Flask. No obstante, esa versión tenía el problema de que los PDF de prueba que se habían recibido tenían diferentes formatos y no se había acordado una estructura común para el contenido, provocando que el texto que se recogía no fuera útil.

\end{itemize}

\section{Intento de publicación de Jupyter Dashboard}

Uno de los objetivos iniciales que se comentaron al comenzar el proyecto consistía en, aparte de conseguir implementar la funcionalidad y la interfaz de usuario en un notebook de Jupyter, poder publicar estos archivos en un formato de aplicación web usando unas librerías llamadas Jupyter Dashboards. La finalidad de estas librerías es la de, teniendo un notebook con la funcionalidad completa, quitar de la pantalla todos los cuadros de código, dejando solo el ``output'' y los elementos interactivos a la vista; ideal para una situación como la que se nos presentaba, en la que la aplicación la iban a usar otros usuarios.

No obstante, los requisitos para poder realizar esta publicación fueron complicándose hasta el punto de tener que descartar esta posibilidad. En lo referente al formato de la salida por pantalla, si que se consiguió configurar el notebook para que tuviera este aspecto de \emph{dashboard}, pero todos los problemas estaban relacionados con la publicación del mismo. Por un lado, era necesario configurar una máquina virtual Docker que ejecutara los comandos necesarios para instalar y configurar todos los elementos que requería este tipo de aplicación. 

Para realizar este proceso, y debido a lo prematuro de estas herramientas (Muchos de los problemas que sufrimos aparecen como issues sin resolver en los respectivos repositorios de GitHub), la opción más viable era seguir el único repositorio de GitHub con guías de despliegue de \emph{dashboards} (\url{ https://github.com/jupyter-incubator/dashboards_setup}) que los propios autores habían facilitado. De estas guías, tres necesitaban de docker para funcionar y la cuarta recurría a CloudFoundry. Mientras que CloudFoundry se descartó porque requería de versiones de pago o versiones de prueba de alguna de las plataformas certificadas que usaban esta tecnología, en el caso de Docker las complicaciones eran de otra naturaleza.

Debido a las condiciones del equipo en el que se realizó el proyecto (Sistema Operativo Windows con Hyper-V), no se podían configurar máquinas docker desde la máquina virtual, porque las máquinas virtuales con Linux que estábamos usando (en este caso, de Oracle VirtualBox) no funcionan con Hyper-V, y las máquinas virtuales de docker necesitaban crearse con Hyper-V activado. Ante la obligación de configurar todo desde el Sistema Operativo anfitrión, un conjunto de incompatibilidades y errores sin aparente solución entre Windows y estas máquinas virtuales, hizo que los recursos necesarios para solventar esta situación fueran demasiado grandes para las limitaciones de tiempo del proyecto.


\section{Omisión de comentarios en el Scrapping}

Una de las funcionalidades que se pretendía incluir en el producto, era la lectura y clasificación por separado de los comentarios de las noticias buscadas. El principal motivo era que los comentarios de una noticia no tenían por qué tener la misma ideología que la noticia, y de hecho muchos de ellos podrían ser de crítica de la propia noticia, aunque se suponga que la mayoría de lectores de un diario en concreto probablemente tenga la misma línea ideológica que el propio medio.


Para realizar este scrapping por separado, se probaron diferentes alternativas, aunque ninguna era muy compatible con las técnicas de \emph{Web Scrapping} que se usaban para leer el resto de la página y, en resumen, provocó la aparición de dos inconvenientes importantes:

\subsection{Uso de Selenium para comentarios ocultos}

En la mayoría de medios en los que se realiza la lectura de noticias, surgió el problema de que al hacer \emph{web scrapping} con \emph{urllib2}, no aparecían los comentarios en el código HTML que llegaba al código del programa. Esto se debe a que en muchos casos los comentarios de los medios se cargan usando herramientas de terceros que dependen de \emph{iframes} y que, al usar un tipo concreto de \emph{request} para coger el código HTML, no se podía alcanzar desde el código Python. 

Por tanto, para atajar este problema, la alternativa más exitosa fue usar Selenium para poder acceder a esos iframe. No obstante, la url con el HTML de los comentarios tenía que cargarse en una pestaña aparte, además de que Selenium abre físicamente el navegador al cliente que esté ejecutando el código, lo cual a su vez generaba otros dos problemas:

\begin{itemize}

\item Según el medio o la herramienta que use el mismo para cargar los comentarios en las noticias, el hecho de que haya que hacer nuevas peticiones con las urls de los comentarios para cada noticia es una operación muy pesada que conllevaba varios minutos de carga en muchos casos, algo totalmente no deseable si la aplicación la va a utilizar algún usuario.

\item Además del tiempo que se tarda en realizar estas operaciones, el usuario además tendría que aguantar que se estuvieran constantemente abriendo pestañas del navegador mientras se realiza la lectura de comentarios, lo cual tampoco es deseable si es un producto que va a usar un tercero.

\end{itemize}
 


\subsection{Falta de comentarios en RSS}

Uno de los principales inconvenientes producidos por el cambio de enfoque de Web Scrapping al RSS de los diarios fue la omisión de lectura de comentarios de las noticias. Debido a las características de este formato, no se incluyen comentarios en las fichas de las noticias en los RSS de los medios. Debido a ello, a pesar de las ventajas que supone este formato en otros aspectos, como facilidad de lectura de noticias y velocidad de la propia lectura, una de las prestaciones que había que sacrificar era la lectura de comentarios.

Incluso en el caso de aquellos medios en los cuáles hay que acceder al enlace que ofrece el RSS para leer el cuerpo de la noticia, si también quisiéramos aprovechar para leer comentarios, se volvería al problema mencionado previamente de falta de opciones sencillas de recogida de los mismos.


Por estos dos motivos, se decidió prescindir de la lectura de comentarios en el producto entregable, a falta de encontrar una alternativa menos intrusiva y con menos costes de tiempo y recursos.